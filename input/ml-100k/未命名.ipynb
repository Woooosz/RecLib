{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "ua = pd.read_csv('ua.base', delimiter='\\t', iterator=False, names=['user','item','ratings','timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "item = pd.read_csv('u.item', delimiter='|', encoding='ISO-8859-1', names=['item','title','release_date', \\\n",
    "                                                                         'video_release_date', 'IMDB_URL','unknown','Action','Adventure',\\\n",
    "                                                                         'Animation','Childrens','Comedy','Crime','Documentary','Drama', \\\n",
    "                                                                         'Fantasy','Film-Noir','Horror','Musical','Mystery','Romance','Sci-Fi', \\\n",
    "                                                                         'Thriller','War','Western'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>title</th>\n",
       "      <th>release_date</th>\n",
       "      <th>video_release_date</th>\n",
       "      <th>IMDB_URL</th>\n",
       "      <th>unknown</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Childrens</th>\n",
       "      <th>...</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>Film-Noir</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Toy%20Story%2...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>GoldenEye (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?GoldenEye%20(...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Four Rooms (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Four%20Rooms%...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Get Shorty (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Get%20Shorty%...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Copycat (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Copycat%20(1995)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   item              title release_date  video_release_date  \\\n",
       "0     1   Toy Story (1995)  01-Jan-1995                 NaN   \n",
       "1     2   GoldenEye (1995)  01-Jan-1995                 NaN   \n",
       "2     3  Four Rooms (1995)  01-Jan-1995                 NaN   \n",
       "3     4  Get Shorty (1995)  01-Jan-1995                 NaN   \n",
       "4     5     Copycat (1995)  01-Jan-1995                 NaN   \n",
       "\n",
       "                                            IMDB_URL  unknown  Action  \\\n",
       "0  http://us.imdb.com/M/title-exact?Toy%20Story%2...        0       0   \n",
       "1  http://us.imdb.com/M/title-exact?GoldenEye%20(...        0       1   \n",
       "2  http://us.imdb.com/M/title-exact?Four%20Rooms%...        0       0   \n",
       "3  http://us.imdb.com/M/title-exact?Get%20Shorty%...        0       1   \n",
       "4  http://us.imdb.com/M/title-exact?Copycat%20(1995)        0       0   \n",
       "\n",
       "   Adventure  Animation  Childrens  ...  Fantasy  Film-Noir  Horror  Musical  \\\n",
       "0          0          1          1  ...        0          0       0        0   \n",
       "1          1          0          0  ...        0          0       0        0   \n",
       "2          0          0          0  ...        0          0       0        0   \n",
       "3          0          0          0  ...        0          0       0        0   \n",
       "4          0          0          0  ...        0          0       0        0   \n",
       "\n",
       "   Mystery  Romance  Sci-Fi  Thriller  War  Western  \n",
       "0        0        0       0         0    0        0  \n",
       "1        0        0       0         1    0        0  \n",
       "2        0        0       0         1    0        0  \n",
       "3        0        0       0         0    0        0  \n",
       "4        0        0       0         1    0        0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理title\n",
    "import gensim, logging,re \n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "item['title'] = item.title.apply(lambda x: re.sub('\\\\(.*?\\\\)|\\\\{.*?}|\\\\[.*?]|(.*?)','',x))\n",
    "titles = item['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "wnl = WordNetLemmatizer() \n",
    "sentences = [title.strip().split(' ') for title in titles]\n",
    "# 提取词干\n",
    "title_set = set([ word for words in sentences for word in words])\n",
    "title2map = {}\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "wnl = WordNetLemmatizer() \n",
    "title2map = {v:wnl.lemmatize(v.lower()) for k,v in enumerate(title_set)}\n",
    "# 去除停顿词\n",
    "from nltk.corpus import stopwords \n",
    "stop = set(stopwords.words('english')) \n",
    "filtered_sentences = []\n",
    "for sentence in sentences:\n",
    "    ans = []\n",
    "    for word in sentence:\n",
    "        if not title2map[word] in stop:\n",
    "            ans.append(title2map[word])\n",
    "    filtered_sentences.append(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-31 15:30:32,825 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
      "2019-05-31 15:30:32,826 : INFO : collecting all words and their counts\n",
      "2019-05-31 15:30:32,826 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-05-31 15:30:32,828 : INFO : collected 2267 word types from a corpus of 3422 raw words and 1682 sentences\n",
      "2019-05-31 15:30:32,830 : INFO : Loading a fresh vocabulary\n",
      "2019-05-31 15:30:32,834 : INFO : effective_min_count=1 retains 2267 unique words (100% of original 2267, drops 0)\n",
      "2019-05-31 15:30:32,836 : INFO : effective_min_count=1 leaves 3422 word corpus (100% of original 3422, drops 0)\n",
      "2019-05-31 15:30:32,845 : INFO : deleting the raw counts dictionary of 2267 items\n",
      "2019-05-31 15:30:32,845 : INFO : sample=0.001 downsamples 20 most-common words\n",
      "2019-05-31 15:30:32,846 : INFO : downsampling leaves estimated 3350 word corpus (97.9% of prior 3422)\n",
      "2019-05-31 15:30:32,851 : INFO : estimated required memory for 2267 words and 10 dimensions: 1314860 bytes\n",
      "2019-05-31 15:30:32,852 : INFO : resetting layer weights\n",
      "2019-05-31 15:30:32,879 : INFO : training model with 3 workers on 2267 vocabulary and 10 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-05-31 15:30:32,884 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-31 15:30:32,885 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-31 15:30:32,888 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-31 15:30:32,889 : INFO : EPOCH - 1 : training on 3422 raw words (3356 effective words) took 0.0s, 693533 effective words/s\n",
      "2019-05-31 15:30:32,893 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-31 15:30:32,894 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-31 15:30:32,896 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-31 15:30:32,897 : INFO : EPOCH - 2 : training on 3422 raw words (3344 effective words) took 0.0s, 603037 effective words/s\n",
      "2019-05-31 15:30:32,902 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-31 15:30:32,903 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-31 15:30:32,905 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-31 15:30:32,906 : INFO : EPOCH - 3 : training on 3422 raw words (3362 effective words) took 0.0s, 625490 effective words/s\n",
      "2019-05-31 15:30:32,911 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-31 15:30:32,912 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-31 15:30:32,915 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-31 15:30:32,915 : INFO : EPOCH - 4 : training on 3422 raw words (3354 effective words) took 0.0s, 613032 effective words/s\n",
      "2019-05-31 15:30:32,920 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-31 15:30:32,921 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-31 15:30:32,924 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-31 15:30:32,924 : INFO : EPOCH - 5 : training on 3422 raw words (3350 effective words) took 0.0s, 719168 effective words/s\n",
      "2019-05-31 15:30:32,925 : INFO : training on a 17110 raw words (16766 effective words) took 0.0s, 366787 effective words/s\n",
      "2019-05-31 15:30:32,926 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
     ]
    }
   ],
   "source": [
    "model = gensim.models.Word2Vec(filtered_sentences, min_count=1, size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dennis/.conda/envs/Reclib/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.00918109, -0.02676832,  0.02179421, -0.01802769, -0.03800369,\n",
       "        0.00241234,  0.01812018,  0.00902718,  0.01317871, -0.03705009],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for sentence in sentences:\n",
    "    ans = []\n",
    "    for word in sentence:\n",
    "        if not title2map[word] in stop:\n",
    "            ans.append(title2map[word])\n",
    "    filtered_sentences.append(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item = item.drop(['video_release_date'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item = item.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ua = pd.merge(ua, item,how='left', on='item')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ua = ua.drop(['IMDB_URL'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = pd.read_csv('u.user', delimiter='|', names=['user','age','gender','occupation','zip_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
